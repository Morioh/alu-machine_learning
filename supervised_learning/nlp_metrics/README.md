# NLP Evaluation Metrics Project

## Resources

### Read or Watch:
- [7 Applications of Deep Learning for Natural Language Processing](#)
- [10 Applications of Artificial Neural Networks in Natural Language Processing](#)
- [A Gentle Introduction to Calculating the BLEU Score for Text in Python](#)
- [BLEU Score](#)
- [Evaluating Text Output in NLP: BLEU at your own risk](#)
- [ROUGE metric](#)
- [Evaluation and Perplexity](#)

### Definitions to Skim:
- BLEU
- ROUGE
- Perplexity

### References:
- BLEU: a Method for Automatic Evaluation of Machine Translation (2002)
- ROUGE: A Package for Automatic Evaluation of Summaries (2004)

## Learning Objectives
By the end of this project, you should be able to explain the following concepts without external resources:

### General:
- What are the applications of natural language processing?
- What is a BLEU score?
- What is a ROUGE score?
- What is perplexity?
- When should you use one evaluation metric over another?

## Requirements

### General:
- Allowed editors: `vi`, `vim`, `emacs`
- All your files will be interpreted/compiled on Ubuntu 16.04 LTS using Python 3 (version 3.5)
- Your files will be executed with `numpy` (version 1.15)
- All your files should end with a new line
- The first line of all your files should be exactly `#!/usr/bin/env python3`
- All of your files must be executable
- A `README.md` file, at the root of the folder of the project, is mandatory
- Your code should follow the `pycodestyle` style (version 2.4)
- All your modules should have documentation (`python3 -c 'print(__import__("my_module").__doc__)'`)
- All your classes should have documentation (`python3 -c 'print(__import__("my_module").MyClass.__doc__)'`)
- All your functions (inside and outside a class) should have documentation (`python3 -c 'print(__import__("my_module").my_function.__doc__)'` and `python3 -c 'print(__import__("my_module").MyClass.my_function.__doc__)'`)
- You are not allowed to use the `nltk` module